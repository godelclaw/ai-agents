%% Towards a complete formalization of PLN
%%
%% Render with: lualatex nuPLN_v1.tex && bibtex nuPLN_v1 && lualatex nuPLN_v1.tex

\documentclass[]{article}
\usepackage{url}
\usepackage{minted}
\usepackage[hyperindex,breaklinks]{hyperref}
\usepackage{breakurl}
\usepackage{listings}
\lstset{basicstyle=\ttfamily\footnotesize,breaklines=false,frame=single}
\usepackage{float}
\restylefloat{table}
\usepackage{longtable}
\usepackage{graphicx}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage[skip=0pt]{subcaption}
\usepackage{circledsteps}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}

% For â‰ž (requires the LuaLaTeX engine)
\usepackage{unicode-math}
\setmathfont{Stix Two Math}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}

\begin{document}

\newcommand{\nuPLN}{\nu\textup{PLN}}
\newcommand{\Bool}{\textup{Bool}}
\newcommand{\T}{\texttt{True}}
\newcommand{\F}{\texttt{False}}
\newcommand{\Domain}{\mathcal{D}}
\newcommand{\Subsetdom}{\mathcal{S}}
\newcommand{\Predicate}{\mathcal{P}}
\newcommand{\Language}{\mathcal{L}}
\newcommand{\Bernouilli}{\mathcal{B}}
\newcommand{\Bernouillip}{\mathcal{B}_p}
\newcommand{\Field}{\mathcal{F}}
\newcommand{\Model}{M}
\newcommand{\Datax}{D_x}
\newcommand{\DataxD}{D_{x\in\Domain}}
\newcommand{\DataS}{D_{\Subsetdom}}
\newcommand{\STV}[2]{<\!#1, #2\!>}
\newcommand{\limp}{\Rightarrow}
\newcommand{\Nat}{\mathbb{N}}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\anymu}{\hat{\mu}}
\newcommand{\anyomega}{\hat{\omega}}
\renewcommand{\measeq}{\doteq}

\title{Towards a Complete Formalization of PLN}
\author{Nil Geisweiller \and Claude\footnote{This document extends Nil Geisweiller's original draft, completing the derivations and adding the convergence theorem.}}
\maketitle

\begin{abstract}
We present $\nuPLN$, a reformulation of Probabilistic Logic Networks (PLN)
grounded in Solomonoff Universal Induction.  By treating PLN truth values
as posterior distributions over a global probability space, we derive the
standard PLN rules from first principles and establish a convergence theorem
analogous to that of Solomonoff induction.  The key insight is that de~Finetti's
representation theorem justifies evidence counts as sufficient statistics,
providing a principled foundation for PLN's truth value calculus.
\end{abstract}

\section{Introduction}
The goal is similar to Solomonoff Universal Induction~\cite{Solomonoff1964},
that is we want to approach a first order (unknown but computable)
distribution $\mu$ given observations, using a second order
(uncomputable but known) distribution $\nu$, called the Universal
Distribution.  In Solomonoff Induction, observations are bit strings
produced by a Turing machine\footnote{Note that even though the sample
space of $\nu$ is made of deterministic Turing machines, $\nu$ can
approximate any computable distribution $\mu$ (thus non-deterministic)
by maintaining an ensemble of such Turing machines.}.  In PLN however,
observations are outcomes from an indexed boolean random variable,
representing the outputs of evaluating a predicate on some inputs.
Such predicate is called the \emph{observable predicate}.  In practice
PLN allows multiple observable predicates however one can assume one
predicate without loss of generality.  Indeed, to emulate multiple
predicates, one can introduce an extra component in the predicate's
domain to ``select'' the predicate of interest.  Also, since it is
observed by a random variable, such predicate is not necessarily
deterministic (though it could be).  As such, one may think of the
observable predicate as being a program drawn from a certain
Probabilistic Programming Language.  In the following section we
formally define the above.

Because this reformulation of PLN departs somewhat from the definition
of PLN in the PLN book~\cite{goertzel2009pln}, we give it a new name, $\nuPLN$.

\section{Definitions}
In its original form, PLN purposely avoids relying on an underlying
global probability distribution.  I am not against this in principle.
I will simply admit that I cannot conceive a complete definition of
PLN that does not rely on such global probability distribution.  I
would also point out that a publication released after the PLN book by
the principal authors of the PLN book, Ben Goertzel and Matt Ikl\'{e},
very much aligns with the idea of a global probability
distribution~\cite{goertzel2025intensional}, and was in fact a great source of
inspiration for writing this very document.  The next subsection is
dedicated to define the global probability distribution which $\nuPLN$
is intended to derive from.

\subsection{Global Probability Distribution}
\label{sec:globalprob}
Let $(\Omega, \Field, \nu)$ be a probability space such that
\begin{itemize}
\item $\Field$ is the event space, a $\sigma$-algebra on $\Omega$.
\item $\nu : \Field \to [0, 1]$ is a universal distribution, further
  defined below.
\item $\Omega$, the set of possible worlds, is the sample space
  associated to $\nu$, such that each element $\anyomega \in \Omega$
  contains
  \begin{enumerate}
  \item a probabilistic predicate $\anymu \in \Language$ over a domain
    $\Domain$, described in a probabilistic programming language
    $\Language$,
  \item a mapping of $\anymu$ from $\Domain$ to Boolean.  For instance
    if $\Domain$ is $\Nat$, then a possible mapping could be
    $(\anymu\ 0) = \T,\ (\anymu\ 1) = \F, \ (\anymu\ 2) = \T, \dots$,
    corresponding so far to a predicate indicating the evenness of a
    natural number.  Note that the world $\anyomega$ contains
    the entire, potentially infinite, mapping, even though in reality
    an observer can only have access to a finite subset of it.
  \end{enumerate}
\end{itemize}
An observer lives in a particular world $\omega \in \Omega$, called
the \emph{true world}, which includes the \emph{true generator} or
\emph{true predicate}, $\mu$, and the \emph{true history}, which is
the complete mapping of evaluations of $\mu$ over the domain
$\Domain$.  Note that since $\mu$ is probabilistic, it does not
deterministically determine the history, thus the true history is just
one possible history among an infinity of histories compatible with
$\mu$.  Note that throughout the document $\omega$ and $\mu$ refer to
the true world and true generator respectively, which is to be
contrasted with $\anyomega$ and $\anymu$ which refer to arbitrary
elements of $\Omega$ and $\Language$ respectively.  Although when it
is clear that the definitions are generic and apply to any arbitrary
world and the true world alike, we will use $\omega$ and $\mu$ as
well.  Since $\mu$ is a probabilistic predicate, its type signature
cannot merely be
$$\mu : \Domain \to \Bool$$ where $\Bool = \{\F, \T\}$.  To capture
its probabilistic nature we give it the following type signature
$$\mu : \Domain \to \Omega \to \Bool$$ in a curried fashion.  Meaning
that given its argument, it produces a boolean random variable.
Therefore the observable predicate can be viewed as an indexed boolean
random variable.  Of course, $\mu$ never gets to be evaluated on a
different world than the one it belongs to, thus we can write
$(\mu\ a)$ while meaning $(\mu\ a\ \omega)$, but we still need to keep
the $\Omega$ argument in order to reason about possible worlds since
the true world is unknown.  Also, in cases where the domain $\Domain$
can be decomposed into multiple components, a curried notation will be
used interchangeably.  So instead of
$$\mu : (\Domain_1 \times \dots \times \Domain_n) \to \Omega \to \Bool$$
the following
$$\mu : \Domain_1 \to \dots \to \Domain_n \to \Omega \to \Bool$$ will
be used.  This will be convenient to express inheritance relationships
between partially applied predicates.  As already hinted, the
application of $\mu$ to an input $x$ is denoted with the traditional
functional programming style
$$(\mu\ x)$$ Thus if the domain is decomposed into subdomains
$\Domain_1$ to $\Domain_n$, applying $\mu$ to all its inputs $x_1$ to
$x_n$ will be denoted
$$(\mu\ x_1\ \dots\ x_n)$$ Likewise for the $\omega$ argument
$$(\mu\ x_1\ \dots\ x_n\ \omega)$$ Such functional programming
notation is used for $\mu$ because it is currying-friendly.  For the
rest, we keep using the traditional mathematical function application
style, such as
$$\nu(E)$$ denoting the application of the probability distribution
$\nu$ to the event $E$.  In case $\mu$ is known to be deterministic,
$\Omega$ could potentially be dropped, but that is not going to be our
working assumption for now.  Additionally to the functional
programming style, we may use parametric notation, so for instance
instead of
$$(\mu\ x_1\ x_2)$$ we may write
$$(\mu_{x_1}\ x_2)$$ where $x_1$ is viewed as a parameter and $x_2$ is
viewed as the argument of $\mu_{x_1}$.\\
With that, let us now define key random variables to access $\Omega$:
\begin{itemize}
\item $\Model : \Omega \to \Language$ with measurable space
  $(\Language, \Field_{\Language})$, where $\Language$ is a certain
  probabilistic programming language and $\Field_{\Language}$ is a
  $\sigma$-algebra on $\Language$.  Thus, $\Model$ takes a world
  $\anyomega \in \Omega$ and outputs the probabilistic program $\anymu
  \in \Language$ generating that world.  Note that this random
  variable is inaccessible from an observer within that world.  An
  observer within that world only has access to a finite record of
  evaluations of $\anymu$.  However, this random variable is important
  to reason about multiple worlds, we suspect it is particularly
  important for higher order reasoning.
\item $\DataxD : \Omega \to \Bool$, a Boolean random variable indexed
  by values in $\Domain$.  Unlike $\Model$, $\DataxD$ is at least
  partially accessible from an observer within that world.  Meaning,
  such observer can gather data for a finite subset $\Subsetdom$ of
  $\Domain$.  In this case $\DataS$ represents a finite family of
  Boolean random variables, corresponding the set of accessible
  observations.  $\Model$ and $\DataxD$ are related by the following
  equality
  $$(\anymu\ x\ \anyomega) = (\Datax\ \anyomega)$$ where $\anyomega
  \in \Omega$ such that $(M\ \anyomega) = \anymu$.  Or simply, in
  curried fashion
  $$(\anymu\ x) = \Datax$$
\end{itemize}
Due to the equality above, the distribution of observations is
entirely determined by a model $\anymu$.  In other words, it suffices
to define a distribution over $\Language$, the prior distribution over
possible models, to define $\nu$ (as far as $M$ and $\Datax$ are
concerned anyway).  Then, relating observations to models can be done
using regular Bayesian inference.  The prior is defined by
$$\nu(M \in L)$$ where $L \in \Field_{\Language}$.  Note how it is
expressed in terms of elements of $\Field_{\Language}$, instead of
elements of $\Language$.  It is because, for the purpose of recovering
PLN with the Bayesian approach, $\Language$ needs to be continuous.\footnote{This requirement is sufficient but not necessary. The Beta posterior can also arise from countable mixtures via Beta-Bernoulli conjugacy and de~Finetti's representation theorem for exchangeable sequences, without requiring a continuous $\Language$.}  I
will explain this in detail, but for now let us use this notation to
formulate Bayes' theorem
$$\nu(M \in L | \DataS) = \frac{\nu(M \in L) \times \nu(\DataS | M \in
  L)}{\nu(\DataS)}$$ where $\Subsetdom$ is a finite subset of
$\Domain$.  For the sake of simplicity, we may drop $M$ since it is
the only random variable that ranges over $\Language$, and simply
write
$$\nu(L | \DataS) = \frac{\nu(L) \times \nu(\DataS |
  L)}{\nu(\DataS)}$$
An example of prior will be given in Section~\ref{sec:bernoulli},
but in general it can be viewed as a parameter of $\nuPLN$.  That is,
given a certain prior of $\nu$ over $\Language$, one can derive a
certain flavor of $\nuPLN$.  Since $(\mu\ x) = \Datax$, a history data
point will be represented as $(\mu\ x) = \T$ or $(\mu\ x) = \F$, and
the usage of the random variable $\Datax$, and especially $\DataS$,
will be reserved in the formulation of $\nu$ to refer to the observed
history.

\subsection{PLN Global Distribution vs Solomonoff Induction}
Note that unlike with Solomonoff Universal Induction, $\anymu$
represents a probabilistic predicate rather than a computable
probability function calculating the probability of any event,
although the latter can be derived from the former.

The \emph{true distribution} in Solomonoff Induction corresponds to
the \emph{real predicate} here.  We prefer to use the word \emph{real}
when denoting objective reality, rather than \emph{true} because
\emph{true predicate} could be understood as a predicate that always
outputs true.

\section{PLN and the Global Distribution}
In Section~\ref{sec:derules} we proceed to derive PLN rules from the
global probability distribution introduced in
Section~\ref{sec:globalprob}, but for now let us recall important
notions of PLN and how to relate them to the global distribution
defined in Section~\ref{sec:globalprob}.

\subsection{Concepts vs Predicates}
The PLN book describes respectively the notions of \emph{concepts} and
\emph{predicates}, and their respective associated relationships
\emph{inheritance} and \emph{implication}.  As explained in Section 2.6
\emph{Higher-Order Logical Relationships} of the PLN book, there is a
perfect isomorphism between concepts and inheritance on one side and
predicates and implication on the other side.  Concerned with
conciseness, we will pick a side, the predicate side, and essentially
forget about the other side, the concept side, for the rest of this
document.  But before we do so let us recall what is a concept, the
inheritance between two concepts, and the isomorphism between concepts
and predicates.

\subsubsection{Concepts and Inheritance}
A concept is a fuzzy (or, as I prefer to say, probabilistic, for
reasons I will explain in Section~\ref{sec:truthvalue}) set, and the
\emph{extensional} inheritance between two concepts is a
probabilitized subset relationship.  Originally, in the PLN book, the
inheritance relationship is defined as an explicit mixture of
extensional and intensional inheritances. We will show however that
they are in fact both the same thing, the extensional inheritance is a
way to approach inheritance solely via \emph{induction}, and
intensional inheritance is a way to approach inheritance solely via
\emph{abduction}.\footnote{This characterization via induction/abduction is non-standard. A more precise formulation, developed in~\cite{goertzel2025intensional}, shows that extensional inheritance emerges as a special case of intensional inheritance when concept properties are singletons. The two are unified through mutual information: $P(W|F) = P(W) \cdot 2^{I(F;W)}$.}  Any one side, extensional or intensional, is good
enough to define the other, so let us pick one, the extensional side,
and define inheritance with it.  The extensional inheritance between
two concepts can be viewed as a probabilitized subset relationship.
It allows to express things like ``most members of a set are also
members of another set''.  For instance one could express in PLN that
90\% of birds fly, with
$$(\texttt{Inheritance}\ \texttt{Bird}\ \texttt{Fly}) \measeq 0.9$$
Such knowledge might have been obtained by observing a finite sample
of birds and whether or not they fly.  Meaning there could be an
uncertainty on the 90\% itself.  To represent such uncertainty PLN
uses a second order distribution, in this case a Beta distribution as
it is an ideal choice to represent the posterior of the parameter of a
Bernoulli distribution given observations.  Under this assumption
only two numbers are required to determine the parameters, $\alpha$
and $\beta$, of the associated Beta distribution.  A \emph{truth
value} called \emph{simple truth value} was created for this purpose
and is thus described by two numbers: a strength (a proxy for a
probability estimate) and a confidence over this strength from which
the $\alpha$ and $\beta$ parameters of the Beta distribution can be
recovered.  For instance, given a simple truth value one may express
that 90\% of birds fly with a confidence of 0.99
$$(\texttt{Inheritance}\ \texttt{Bird}\ \texttt{Fly})\ \measeq\ \STV{0.9}{0.99}$$
where 0.9 is the strength and 0.99 is the confidence.  The confidence
is a value between 0 and 1 that actually encodes the sample size that
was used to obtained the strength.  The higher the sample size, the
higher the confidence.  More information about that will be provided
in Section~\ref{sec:truthvalue} but for now let us just leave it at that as it
is enough for what we are concerned with in this Section which is the
isomorphism between concepts and predicates.

\subsubsection{Isomorphism between Concepts and Predicates}
To every concept one can associate a predicate and vice versa.  To go
from concept to predicate one can use the \emph{indicator function},
and to go from predicate to concept one can use the \emph{satisfying
set}.  These notions are well known for crisp predicates and sets and
thus will not be detailed any further here.  The only difference in
PLN is that concepts are probabilistic, meaning that a probability (or
potentially a second order probability) can be attached to the
membership of an element to a concept.  Likewise, predicates are
probabilistic in the sense that a (second order) probability can be
attached to the evaluation of an argument to a predicate.  As one
would expect the isomorphism also applies between the inheritance
relationship on the concept side and the implication relationship on
the predicate side.  So for instance, on the predicate side one can
express the same inheritance relationship between birds and fly as
follows
$$(\texttt{Implication}\ \texttt{IsBird}\ \texttt{DoesFly})\ \measeq\ \STV{0.9}{0.99}$$
where $\texttt{IsBird}$ and $\texttt{DoesFly}$ have been obtained by
taking the indicator functions of $\texttt{Bird}$ and $\texttt{Fly}$.
As mentioned earlier, we will drop the concept side and only focus on
the predicate side for the remaining of the document.

\subsection{Relating Predicates to \texorpdfstring{$\mu$}{mu}}
As explained in Section~\ref{sec:globalprob} there is only one global
predicate, $\mu$.  To manipulate multiple predicates we can simply
introduce a additional parameter in the domain of $\mu$ indicating
predicates.  Let us call this subdomain $\Predicate$ which ranges over
symbols representing predicates, in this case $\mu$ may have the type
signature
$$\mu : \Predicate \to \Domain \to \Omega \to \Bool$$ So for instance
to express that a cat is a mammal, traditionally represented as
$$\textit{Cat} \limp \textit{Mammal}$$ one may use the following
parametric notation of $\mu$
$$\mu_{\textit{Cat}} \limp \mu_{\textit{Mammal}}$$ Likewise, to
represent the evaluation of the predicate \textit{Cat} over a certain
cat instance, $\textit{cat}_{123}$, one may use
$$(\mu_{\textit{Cat}}\ \textit{cat}_{123})$$ corresponding to
the traditional representation
$$(\textit{Cat}\ \textit{cat}_{123})$$ where $\textit{cat}_{123} \in
\Domain$.

\subsection{Truth Value as Posterior Distribution}
\label{sec:truthvalue}
A PLN truth value is not merely a point estimate of probability; it
encodes an entire posterior distribution over possible probability
values.  This is the key to understanding why PLN uses two numbers
(strength and confidence) rather than one.

The justification for this encoding comes from de~Finetti's
representation theorem~\cite{definetti1937}.  For an infinite
exchangeable sequence of binary observations, de~Finetti showed that
such a sequence can be represented as a mixture of i.i.d.\ Bernoulli
sequences.  A crucial consequence is that the \emph{counts} of
positive and negative observations, denoted $(n^+, n^-)$, are
\emph{sufficient statistics}.  That is, given the counts, the order in
which observations arrived is irrelevant for inference.

This result has profound implications for PLN.  It means that evidence
counts $(n^+, n^-)$ contain all the information needed for Bayesian
updating.  When we assume a Beta prior $\text{Beta}(\alpha, \beta)$
over the unknown probability parameter $p$, the posterior after
observing $n^+$ positive and $n^-$ negative outcomes is:
$$\text{Beta}(\alpha + n^+, \beta + n^-)$$

The PLN simple truth value $\STV{s}{c}$ encodes this posterior as follows:
\begin{itemize}
\item The \emph{strength} $s$ is the posterior mean:
  $$s = \frac{\alpha + n^+}{\alpha + \beta + n^+ + n^-}$$
  Under the common choice of a uniform prior ($\alpha = \beta = 1$) or
  Jeffreys prior ($\alpha = \beta = \frac{1}{2}$), this simplifies
  approximately to $s \approx \frac{n^+}{n^+ + n^-}$ for large sample
  sizes.

\item The \emph{confidence} $c$ encodes the sample size relative to a
  constant $\kappa$ (often called the ``lookahead'' or ``weight of
  prior''):
  $$c = \frac{n^+ + n^-}{n^+ + n^- + \kappa}$$
  As the sample size grows, confidence approaches 1.  When no
  observations have been made, confidence is 0.
\end{itemize}

The choice of $\kappa$ reflects how quickly we gain confidence from
observations.  A smaller $\kappa$ means faster convergence to high
confidence; a larger $\kappa$ means more conservatism.

I would emphasize that this is not merely a convenient encoding---it
is the \emph{correct} encoding given the assumptions of exchangeability
and Beta-Bernoulli conjugacy.  The fact that PLN arrived at this
encoding through practical considerations, while Bayesian probability
theory derives it from first principles, is a reassuring convergence.

\subsection{Statement versus Judgement}
\label{sec:statjudge}
Like in NAL, a PLN \emph{statement} designates a logical statement
without truth value, such as
$$P \limp Q$$ While a PLN \emph{judgment} designates a PLN statement
with a truth value attached to it, such as
$$P \limp Q\ \measeq\ \STV{0.9}{0.8}$$

\section{Deriving PLN Rules}
\label{sec:derules}
Our goal here is to derive every PLN rule in the PLN book from the
global distribution that has been defined in
Section~\ref{sec:globalprob}.  By doing so we hope not only to
provide a clear unambiguous definition for each rule, but also an
ideal to approach as using a global distribution should give us the
means to derive a convergence theorem \`{a} la Solomonoff.

\subsection{Predicate Direct Introduction}
\label{sec:bernoulli}
This rule is meant to calculate the truth value corresponding to a
Predicate from direct observations.  Its truth value can be understood
as the marginal probability of a predicate to be true, irrespective of
the inputs.  It is a subcase of the Implication Direct Introduction
presented in Section~\ref{sec:impldirect} where the implicant is the
\emph{Universal Predicate} (a predicate that is always true), but is
described here as its own rule to simplify the presentation.  Indeed,
it should be easier to understand the Implication Direct Introduction
rule after understanding the Predicate Direct Introduction rule.

To derive the predicate direct introduction rule we consider the
posterior probability of a Bernoulli process with parameter $p$ given
all available observations of the predicate in question.  Let us begin
with $\mu$ itself.  In order to formulate this posterior we need to
assume that $\Language$ has a Bernoulli sampler in its set of
operators.  Let $\Bernouilli$ be the subset of programs of $\Language$
consisting of a single Bernoulli call, thus comprised of the
following programs
\begin{minted}{scheme}
  (Bernoulli p)
\end{minted}
where \mintinline{scheme}{p} is the parameter of the Bernoulli
distribution ranging over $[0, 1]$.  Such probabilistic program, when
executed, outputs $\T$ with a probability of \mintinline{scheme}{p} or
$\F$ with a probability of $1 - p$.  Let
$\Field_{\Bernouilli}$ be a Borel $\sigma$-algebra on $\Bernouilli$.
Let us assume that $\Field_{\Bernouilli}$ is a subfield of
$\Field_{\Language}$.  We claim that if $\mu$ is restricted to
the programs in $\Bernouilli$ then the posterior of
\mintinline{scheme}{p} corresponds to the truth value of $\mu$,
expressed as follows
$$\nu(L_{\Bernouilli} | \DataS) = \frac{\nu(L_{\Bernouilli}) \times
  \nu(\DataS | L_{\Bernouilli})}{\nu(\DataS)}$$ where $L_{\Bernouilli}
\in \Field_{\Bernouilli}$.

Now let us make this concrete.  Suppose we have observed a finite
subset $\Subsetdom \subset \Domain$ of evaluations, yielding $n^+$
positive outcomes (where $(\mu\ x) = \T$) and $n^-$ negative outcomes
(where $(\mu\ x) = \F$).  Under the assumption that $\mu$ is drawn
from $\Bernouilli$, the likelihood of these observations given
parameter $p$ is:
$$\nu(\DataS | p) = p^{n^+} (1-p)^{n^-}$$

If we place a Beta prior $\text{Beta}(\alpha, \beta)$ on $p$, the
posterior is $\text{Beta}(\alpha + n^+, \beta + n^-)$ with density:
$$f(p | \DataS) \propto p^{\alpha + n^+ - 1}(1-p)^{\beta + n^- - 1}$$

The truth value is then:
\begin{itemize}
\item Strength: $s = \frac{\alpha + n^+}{\alpha + \beta + n^+ + n^-}$
  (the posterior mean)
\item Confidence: $c = \frac{n^+ + n^-}{n^+ + n^- + \kappa}$ (encoding
  sample size)
\end{itemize}

Under the Jeffreys prior $\alpha = \beta = \frac{1}{2}$, the strength
becomes:
$$s = \frac{\frac{1}{2} + n^+}{1 + n^+ + n^-}$$
which is precisely the Krichevsky-Trofimov estimator used in universal
prediction~\cite{hutter2005universal}.  This is not a coincidence---both PLN and
universal prediction are solving the same problem of optimal inference
from exchangeable binary data.

\subsection{Implication Direct Introduction}
\label{sec:impldirect}
This rule is not explicitly stated as such in the PLN book but can be
derived from iteratively applying induction and revision, and reflects
the formula of extensional inheritance/implication given in Section
2.4.1 \emph{The Semantics of Inheritance} of the PLN book, at least
the strength part.  To obtain the confidence part we assume that the
second order distribution is a Beta distribution, like in Section
4.2 \emph{From Imprecise Probabilities to Indefinite Probabilities} of
the PLN book.  In order to derive a Beta distribution as second order
distribution we can assume an underlying Bernoulli process with
parameter $p$ with a Beta distribution as prior.  The Jeffreys prior
where $\alpha=\beta=\frac{1}{2}$ is often the default choice.  Given
the PLN statement
$$P \limp Q$$ let us express its truth value as the posterior
probability of the parameter $p$ of the underlying Bernoulli process.
In order to map a Bernoulli process onto an implication we zoom-in to
the data points where $P$ is true.

Concretely, let $\Subsetdom_P \subseteq \Subsetdom$ be the subset of
observations where predicate $P$ evaluates to true.  Within this
subset, let:
\begin{itemize}
\item $n^+_{PQ}$ = number of cases where both $P$ and $Q$ are true
\item $n^-_{PQ}$ = number of cases where $P$ is true but $Q$ is false
\end{itemize}

The implication $P \limp Q$ is then treated as a Bernoulli process
over the restricted domain $\Subsetdom_P$, with the same Bayesian
update:
\begin{itemize}
\item Strength: $s = \frac{\alpha + n^+_{PQ}}{\alpha + \beta + n^+_{PQ} + n^-_{PQ}}$
\item Confidence: $c = \frac{n^+_{PQ} + n^-_{PQ}}{n^+_{PQ} + n^-_{PQ} + \kappa}$
\end{itemize}

Note that the confidence depends only on the number of observations
where $P$ is true, not on the total number of observations.  This
correctly reflects that we can only learn about $P \limp Q$ from cases
where $P$ holds.

\subsection{Priors}
\label{sec:priors}
Typical priors for the Beta distribution include:
\begin{itemize}
\item \textbf{Haldane prior}: $\alpha = \beta = 0$ (improper, maximally uninformative)
\item \textbf{Jeffreys prior}: $\alpha = \beta = \frac{1}{2}$ (invariant under reparametrization)
\item \textbf{Bayes/Uniform prior}: $\alpha = \beta = 1$ (flat prior on $[0,1]$)
\end{itemize}

The PLN strength formula $s = n^+ / (n^+ + n^-)$ corresponds to the
Haldane prior.  The Jeffreys prior $\alpha = \beta = \frac{1}{2}$
yields the Krichevsky-Trofimov estimator, which has optimal properties
for universal prediction.  In practice, the choice of prior matters
most when sample sizes are small; for large $n^+ + n^-$, all proper
priors converge to the same posterior.

\subsection{Deduction Rule}
\label{sec:deduction}
The PLN deduction rule computes the truth value of $P \limp R$ given
the truth values of $P \limp Q$ and $Q \limp R$.  Unlike the direct
introduction rules which derive truth values from observations, the
deduction rule derives truth values from other truth values.

I would emphasize that the deduction formula is not a heuristic---it
is derivable from the law of total probability.  Let $s_{PQ}$,
$s_{QR}$, and $s_{PR}$ denote the strengths of $P \limp Q$, $Q \limp
R$, and $P \limp R$ respectively.  Let $p_Q$ and $p_R$ denote the
marginal probabilities of $Q$ and $R$.

By the law of total probability:
$$P(R|P) = P(R|P,Q) \cdot P(Q|P) + P(R|P,\neg Q) \cdot P(\neg Q|P)$$

Under the conditional independence assumption $P(R|P,Q) \approx
P(R|Q)$ and $P(R|P,\neg Q) \approx P(R|\neg Q)$, and using $P(R|\neg
Q) = \frac{P(R) - P(Q) \cdot P(R|Q)}{1 - P(Q)}$, we obtain:
$$s_{PR} = s_{PQ} \cdot s_{QR} + (1 - s_{PQ}) \cdot \frac{p_R - p_Q \cdot s_{QR}}{1 - p_Q}$$

This is precisely the PLN deduction strength formula.  The confidence
of the conclusion is typically taken as the minimum of the input
confidences, reflecting that a chain is only as strong as its weakest
link.

\subsection{Induction Rule (Source Rule)}
\label{sec:induction}
The PLN \emph{induction} rule computes the truth value of $A \limp C$
given $B \limp A$ and $B \limp C$.  The key insight is that this is
simply Bayes' rule followed by deduction.

Given $B \limp A$ with strength $s_{BA}$, we use Bayes' rule to obtain
$A \limp B$:
$$s_{AB} = \frac{s_{BA} \cdot p_B}{p_A}$$

Then we apply the deduction formula to $A \limp B$ and $B \limp C$:
$$s_{AC} = s_{AB} \cdot s_{BC} + (1 - s_{AB}) \cdot \frac{p_C - p_B \cdot s_{BC}}{1 - p_B}$$

This rule is also called the \emph{source rule} because $B$ is the
common source---arrows fan out from $B$ to both $A$ and $C$.  In
category-theoretic terms, we are completing a cospan $A \leftarrow B
\to C$ to obtain $A \to C$.

\subsection{Abduction Rule (Sink Rule)}
\label{sec:abduction}
The PLN \emph{abduction} rule computes the truth value of $A \limp C$
given $A \limp B$ and $C \limp B$.  Like induction, this is Bayes'
rule followed by deduction.

Given $C \limp B$ with strength $s_{CB}$, we use Bayes' rule to obtain
$B \limp C$:
$$s_{BC} = \frac{s_{CB} \cdot p_C}{p_B}$$

Then we apply the deduction formula to $A \limp B$ and $B \limp C$:
$$s_{AC} = s_{AB} \cdot s_{BC} + (1 - s_{AB}) \cdot \frac{p_C - p_B \cdot s_{BC}}{1 - p_B}$$

This rule is also called the \emph{sink rule} because $B$ is the
common sink---arrows fan in to $B$ from both $A$ and $C$.  In
category-theoretic terms, we are completing a span $A \to B \leftarrow
C$ to obtain $A \to C$.

\subsection{Conjunction Introduction}
\label{sec:conjunction}
Given $A \measeq TV_A$ and $B \measeq TV_B$, infer $A \land B \measeq
TV_{A\land B}$.  Unlike the inference rules above, which involve
implications, conjunction involves combining two predicates directly.

The key insight is that conjunction follows a \emph{hypergeometric}
distribution.  Consider the discrete case where:
\begin{itemize}
\item $n$ is the size of the universe,
\item $a = |A|$ is the number of elements satisfying $A$,
\item $b = |B|$ is the number of elements satisfying $B$,
\item $k = |A \land B|$ is the number of elements satisfying both.
\end{itemize}

The probability of exactly $k$ elements in the intersection is:
$$P(|A\land B|=k) = \frac{\binom{a}{k} \times \binom{n-a}{b-k}}{\binom{n}{b}}$$

This is the hypergeometric probability mass function.  The cumulative
distribution function is:
$$P(|A\land B| \leq k) = \sum_{i=0}^k \frac{\binom{a}{i} \times
  \binom{n-a}{b-i}}{\binom{n}{b}}$$

\subsubsection{The Mode Bounds (Fr\'{e}chet Bounds)}
The mode of the hypergeometric satisfies:
$$\max(0, a + b - n) \leq \text{mode} \leq \min(a, b)$$

In probability terms (dividing by $n$):
$$\max(0, P(A) + P(B) - 1) \leq P(A \land B) \leq \min(P(A), P(B))$$

These are the \emph{Fr\'{e}chet bounds}, which hold for \emph{any}
joint distribution, not just the hypergeometric.  PLN consistency is
equivalent to respecting these bounds.

\subsubsection{The Continuous Limit}
The continuous case is obtained by taking $n \to \infty$ with fixed
probabilities $p_A = a/n$ and $p_B = b/n$.  Using Stirling's
approximation on the factorials leads to a continuous density over the
conjunction probability.  The key insight is that the discrete
hypergeometric PMF converges to a continuous density; the Fr\'{e}chet
bounds hold in both cases.

\subsection{Implicant Conjunction Introduction}
\label{sec:implicantconj}
$$A \to C, B \to C \vdash (A \land B) \to C$$

If $A$ implies $C$ and $B$ implies $C$, what can we say about $(A
\land B)$ implying $C$?

\subsubsection{Independence Assumptions}
We assume:
\begin{enumerate}
\item $A$ and $B$ are \emph{globally independent}: $P(A,B) = P(A) \times P(B)$
\item $A$ and $B$ are \emph{conditionally independent given $C$}: $P(A,B|C) = P(A|C) \times P(B|C)$
\end{enumerate}

\subsubsection{Derivation}
By Bayes' formula:
$$P(C|A,B) = \frac{P(A,B|C) \times P(C)}{P(A,B)}$$

Using assumptions 1 and 2:
$$P(C|A,B) = \frac{P(A|C) \times P(B|C) \times P(C)}{P(A) \times P(B)}$$

Applying Bayes to $P(A|C)$ and $P(B|C)$:
$$P(A|C) = \frac{P(C|A) \times P(A)}{P(C)}, \quad P(B|C) = \frac{P(C|B) \times P(B)}{P(C)}$$

Substituting:
$$P(C|A,B) = \frac{P(C|A) \times P(C|B)}{P(C)}$$

This elegant formula shows that under independence, the strength of
$(A \land B) \to C$ is the product of the individual implication
strengths divided by the marginal probability of $C$.

Note that this formula can exceed 1 when $P(C)$ is small and both
$P(C|A)$ and $P(C|B)$ are high.  In practice, cap at 1:
$$s_{(A\land B)\to C} = \min\left(1, \frac{s_{A\to C} \times s_{B\to C}}{p_C}\right)$$

\subsection{Negation}
\label{sec:negation}
The PLN negation swaps positive and negative evidence:
$$\neg(n^+, n^-) = (n^-, n^+)$$

This gives the expected probabilistic behavior:
\begin{itemize}
\item Strength inverts: $s(\neg A) = 1 - s(A)$
\item Confidence unchanged: $c(\neg A) = c(A)$
\end{itemize}

Note that this is \emph{not} the Heyting complement $a \Rightarrow \bot$.
The PLN negation is involutive ($\neg\neg A = A$), while the Heyting
complement is not.  This distinction is important: Evidence forms a
Heyting algebra, but the probabilistic negation is a separate operation.

\subsection{Disjunction Introduction}
\label{sec:disjunction}
Given $A \measeq TV_A$ and $B \measeq TV_B$, infer $A \lor B \measeq
TV_{A\lor B}$.

\subsubsection{Via De Morgan's Law}
$$P(A \lor B) = 1 - P(\neg A \land \neg B)$$

Using PLN negation (evidence swap) and conjunction:
$$\text{Evidence}(A \lor B) = \neg(\neg A \otimes \neg B)$$

\subsubsection{Via Inclusion-Exclusion}
$$P(A \lor B) = P(A) + P(B) - P(A \land B)$$

Under independence, $P(A \land B) = P(A) \times P(B)$, so:
$$s_{A\lor B} = s_A + s_B - s_A \times s_B$$

\subsubsection{Fr\'{e}chet Bounds for Disjunction}
Without independence assumption:
$$\max(P(A), P(B)) \leq P(A \lor B) \leq \min(1, P(A) + P(B))$$

The lower bound ensures disjunction is at least as likely as either
disjunct.  The upper bound caps at 1.

\subsection{Revision Rule}
\label{sec:revision}
The Revision Rule combines evidence from independent sources:
$$D_1 \oplus D_2 = (n^+_1 + n^+_2, n^-_1 + n^-_2)$$

This is the \emph{hplus} operation on Evidence.

\subsubsection{Strength as Weighted Average}
The combined strength is a weighted average of input strengths:
$$s_{\text{combined}} = \frac{n_1 \times s_1 + n_2 \times s_2}{n_1 + n_2}$$

where $n_i = n^+_i + n^-_i$ is the total evidence count.

\subsubsection{Connection to Bayesian Updating}
The Revision Rule corresponds exactly to Beta conjugate updating:
\begin{itemize}
\item Prior: $\text{Beta}(\alpha_0, \beta_0)$
\item Observation 1: $n^+_1$ successes, $n^-_1$ failures $\to$ Posterior:
  $\text{Beta}(\alpha_0 + n^+_1, \beta_0 + n^-_1)$
\item Observation 2: $n^+_2$ successes, $n^-_2$ failures $\to$ Final:
  $\text{Beta}(\alpha_0 + n^+_1 + n^+_2, \beta_0 + n^-_1 + n^-_2)$
\end{itemize}

This is why PLN Evidence is the \emph{natural} representation for
Bayesian inference: the algebraic hplus operation \emph{is} conjugate
updating.

\subsection{Similarity}
\label{sec:similarity}
Similarity is a \emph{symmetric} relationship: $\text{sim}(A, B) =
\text{sim}(B, A)$.

\subsubsection{Set-Theoretic Definition}
$$\text{sim}(A, B) = \frac{|A \cap B|}{|A \cup B|}$$

\subsubsection{From Two Inheritances}
Given $s_{AC} = P(C|A)$ and $s_{CA} = P(A|C)$, compute:
$$\text{sim}_{AC} = \frac{1}{\frac{1}{s_{AC}} + \frac{1}{s_{CA}} - 1}
  = \frac{s_{AC} \times s_{CA}}{s_{AC} + s_{CA} - s_{AC} \times s_{CA}}$$

This is a harmonic-like mean of the two directed strengths.

\subsubsection{Transitive Similarity}
Given $\text{sim}_{AB}$, $\text{sim}_{BC}$, and term probabilities,
compute $\text{sim}_{AC}$ by:
\begin{enumerate}
\item Convert similarities to inheritances
\item Apply deduction in both directions
\item Combine back to similarity
\end{enumerate}

\subsection{Modus Ponens}
\label{sec:modusponens}
Classical modus ponens: from $P \limp Q$ and $P$, infer $Q$.

In PLN terms: Given $P(B|A)$ and $P(A)$, infer $P(B)$.

\subsubsection{The Formula}
By the law of total probability:
$$P(B) = P(B|A) \times P(A) + P(B|\neg A) \times P(\neg A)$$

The challenge: we typically don't know $P(B|\neg A)$.  PLN uses a
default ``background probability'' parameter $c$:
$$s_B = s_{A \limp B} \times s_A + c \times (1 - s_A)$$

\subsubsection{Special Cases}
\begin{itemize}
\item When $s_A = 1$ (certain premise): $s_B = s_{A \limp B}$
\item When $s_A = 0$ (false premise): $s_B = c$
\end{itemize}

\subsubsection{Modus Tollens}
From $P(P \limp Q)$ and $P(\neg Q)$, infer $P(\neg P)$.

This is equivalent to modus ponens on the contrapositive $\neg Q \limp
\neg P$ with strength $P(\neg P | \neg Q)$.

\subsection{The Inference Triad}
\label{sec:triad}
The three syllogistic rules---deduction, induction, and
abduction---form a unified triad:
\begin{center}
\begin{tabular}{lll}
\textbf{Rule} & \textbf{Premises} & \textbf{Method} \\
\hline
Deduction & $A \limp B$, $B \limp C$ & Direct composition \\
Induction & $B \limp A$, $B \limp C$ & Bayes on 1st premise, then deduction \\
Abduction & $A \limp B$, $C \limp B$ & Bayes on 2nd premise, then deduction \\
\end{tabular}
\end{center}

This unification is not a heuristic---it follows from basic probability
theory.  Bayes' rule converts between $P(A|B)$ and $P(B|A)$, and
deduction composes conditional probabilities.  The three rules are
simply different entry points into the same compositional structure.

\section{The \texorpdfstring{$\nuPLN$}{nuPLN} Theorem}
\label{sec:convergence}

\subsection{Background: Solomonoff Optimality}

Hutter~\cite{hutter2003optimality} proved that Solomonoff's universal
prior is \emph{optimal} for sequence prediction: it minimizes expected
loss (for any reasonable loss function) among all predictors, assuming
only that the data source is computable.  The Solomonoff predictor
works by maintaining a mixture over all computable hypotheses,
weighted by algorithmic probability.

However, this optimal predictor has two practical obstacles:
\begin{enumerate}
\item It is \emph{uncomputable} (the halting problem).
\item It requires tracking the \emph{full observation history}---the
  predictor state is the entire past sequence.
\end{enumerate}

\subsection{The Domain Restriction}

The key observation is that for certain restricted domains, the second
obstacle vanishes.  Specifically, when the domain consists of
\emph{exchangeable binary sequences}, the predictor state compresses
from ``full history'' to just two numbers.

\begin{theorem}[Restricted Solomonoff Collapses to Counts]
\label{thm:pln_optimal}
Let $M$ be a Solomonoff-style prior \emph{restricted to exchangeable
programs}---formally, a monotone machine $U$ with a prefix-free
program set where the induced semimeasure $\mu$ satisfies: for any
permutation $\pi$, $\mu(x_1, \ldots, x_n) = \mu(x_{\pi(1)}, \ldots,
x_{\pi(n)})$.

Then for any two observation sequences $x_1, x_2$ of the same length
with the same counts $(n^+, n^-)$:
\begin{enumerate}
\item \textbf{Same probability}: $\mu(x_1) = \mu(x_2)$
\item \textbf{Same predictor}: For any $b \in \{\texttt{true}, \texttt{false}\}$,
  $$\frac{\mu(x_1 \cdot b)}{\mu(x_1)} = \frac{\mu(x_2 \cdot b)}{\mu(x_2)}$$
\end{enumerate}
\end{theorem}

The theorem says: under the exchangeability restriction, the
Solomonoff predictor $\mu(x \cdot b)/\mu(x)$ depends \emph{only} on
$(n^+, n^-)$, not on the order of observations.  The sufficient
statistic is the count pair---which is precisely PLN Evidence.

\subsection{The Representation Theorem}

What is the \emph{form} of the predictor?  De Finetti's representation
theorem~\cite{definetti1937} answers this:

\begin{theorem}[De Finetti's Theorem]
\label{thm:definetti}
An infinite sequence of binary random variables is exchangeable if and
only if it can be represented as a mixture of i.i.d.\ Bernoulli
sequences:
$$\text{InfiniteExchangeable}(X, \mu) \iff \exists M : \text{BernoulliMixture}.\ \text{Represents}(M, X, \mu)$$
\end{theorem}

The ``BernoulliMixture'' is a probability measure $\nu$ on $[0,1]$
such that:
$$\mu(x_1, \ldots, x_n) = \int_0^1 p^{n^+}(1-p)^{n^-}\, d\nu(p)$$
The mixing measure $\nu$ represents uncertainty about the ``true''
Bernoulli parameter $p$.

\subsection{The Complete Chain}

Combining these results yields the full picture:

\begin{enumerate}
\item \textbf{Solomonoff optimality} (Hutter): The universal prior is
  optimal for sequence prediction.
\item \textbf{Exchangeability restriction} (Theorem~\ref{thm:pln_optimal}):
  Under exchangeability, the predictor depends only on counts $(n^+, n^-)$.
\item \textbf{De Finetti representation} (Theorem~\ref{thm:definetti}):
  Exchangeable sequences are Bernoulli mixtures.
\item \textbf{Beta-Bernoulli conjugacy}: With a Beta$(\alpha, \beta)$
  prior on the Bernoulli parameter $p$, the posterior after observing
  $(n^+, n^-)$ is Beta$(\alpha + n^+, \beta + n^-)$.
\item \textbf{PLN strength}: The posterior mean is $(\alpha +
  n^+)/(\alpha + \beta + n^+ + n^-)$.  PLN's strength formula $n^+ /
  (n^+ + n^-)$ corresponds to the improper prior $\alpha = \beta = 0$,
  and converges to any proper posterior mean as sample size increases.
\end{enumerate}

This chain is formalized in Lean~4 as the \texttt{nupln\_master\_chain}
theorem, which explicitly invokes each step by name.  The proof
constructs the mixing measure via the Hausdorff moment theorem applied
to the de~Finetti moment sequence.

\subsection{Conceptual Summary}

PLN Evidence $(n^+, n^-)$ is not an approximation or heuristic.  It is
the \emph{exact} sufficient statistic for Bayesian inference over
exchangeable binary sequences.  The PLN strength formula $n^+/(n^+ +
n^-)$ is the maximum likelihood estimator, corresponding to an
improper (Haldane) prior; it converges to any proper Bayesian
posterior mean as sample size increases.

When Solomonoff induction is restricted to exchangeable binary
domains, it \emph{becomes} PLN.  The ``arbitrary program mixture'' of
Solomonoff collapses to the Beta mixture of de Finetti, and the
predictor state compresses from ``full history'' to $(n^+, n^-)$.

This justifies using PLN for domains where exchangeability holds---the
inference is not approximate but optimal.  The domain restriction is
the hypothesis; the simplification is the theorem.

\section{The Algebraic Foundations of Evidence}
\label{sec:algebra}

The Evidence structure $(n^+, n^-)$ is not an ad-hoc encoding.  It arises
naturally from the intersection of three mathematical frameworks, each
providing a different perspective on the same underlying structure.

\subsection{Evidence as a Quantale}

A \emph{quantale} is a complete lattice equipped with an associative
multiplication that distributes over arbitrary joins:
$$a \otimes \left(\bigvee_i b_i\right) = \bigvee_i (a \otimes b_i)$$

Evidence with the \emph{tensor} product forms a commutative quantale:
$$(n^+_1, n^-_1) \otimes (n^+_2, n^-_2) = (n^+_1 \cdot n^+_2, n^-_1 \cdot n^-_2)$$

The fundamental quantale law for implications is the \emph{transitivity} property:
$$(A \to B) \otimes (B \to C) \leq (A \to C)$$

This is precisely the PLN deduction rule at the evidence level!  The multiplicative
nature of tensor captures how uncertainty compounds when chaining implications.

\subsection{Evidence as a Heyting Algebra}

Evidence is also a complete Heyting algebra (a \emph{frame}).  Unlike Boolean
algebras, Heyting algebras have non-involutive negation: $\neg\neg a \neq a$
in general.  This is proven by explicit counterexample in our formalization.

The Heyting structure explains why Evidence requires \emph{two} dimensions.
A single probability $p \in [0,1]$ cannot capture both ``how likely'' and
``how certain'' we are.  The pair $(n^+, n^-)$ encodes:
\begin{itemize}
\item \emph{Strength}: $s = n^+ / (n^+ + n^-)$ (the probability estimate)
\item \emph{Confidence}: proportional to $n^+ + n^-$ (the certainty)
\end{itemize}

To see why one dimension is insufficient, consider $(1, 1)$ and $(100, 100)$.
Both have strength $\frac{1}{2}$, yet the latter represents far more evidence.
A single probability cannot distinguish these cases.  More generally, for any
strength $s \in (0,1)$, infinitely many evidence values $(k \cdot s, k \cdot (1-s))$
produce that same strength---the ``fiber'' over $s$ is infinite.  The second
dimension is not redundant; it carries essential information about certainty.

The Heyting residuation law holds:
$$a \leq (b \Rightarrow c) \iff (a \wedge b) \leq c$$
providing a logical interpretation of evidence combination.

\subsubsection{Strength is NOT Monotone}
A subtle but critical insight: strength does \emph{not} respect the
Evidence partial order.

\textbf{Counterexample}: $(1, 0) \leq (1, 1)$ in the Evidence order
(coordinatewise), but:
$$s(1, 0) = \frac{1}{1+0} = 1 > \frac{1}{2} = \frac{1}{1+1} = s(1, 1)$$

Adding negative evidence \emph{decreases} strength while
\emph{increasing} in the partial order.  This means strength is not a
K\&S valuation on Evidence.

Confidence, however, \emph{is} monotone: more evidence (in either
direction) increases confidence.  This asymmetry is fundamental---strength
measures ``what we believe,'' confidence measures ``how strongly we
believe it.''

\subsubsection{Connection to Knuth-Skilling Theory}
Evidence connects to Knuth \& Skilling's ``Foundations of
Inference''~\cite{knuthskilling2012} at multiple levels:

\begin{itemize}
\item \textbf{PlausibilitySpace}: Evidence is a distributive lattice
  with $\top$ and $\bot$, so K\&S valuations and conditional
  plausibility are well-defined.
\item \textbf{Not Boolean}: Evidence is a Heyting algebra, not a
  Boolean algebra.  The law of excluded middle fails: there exist
  evidence values $e$ such that $e \vee \neg e \neq \top$.
\item \textbf{Intuitionistic Probability}: This gives ``intuitionistic
  probability theory'' where $P(\neg A) \neq 1 - P(A)$ in general.
\end{itemize}

The K\&S product rule derivations (requiring Boolean structure) do not
directly apply to the Evidence lattice.

\textbf{Resolution}: PLN operates at \emph{two distinct levels}:
\begin{enumerate}
\item \textbf{Event level}: The global probability space $(\Omega,
  \mathcal{F}, \nu)$ where $\mathcal{F}$ IS a Boolean $\sigma$-algebra.
  Standard Bayesian probability applies here.
\item \textbf{Evidence level}: The lattice of Evidence values $(n^+,
  n^-)$ is Heyting.  This describes the \emph{information ordering}
  (``more evidence''), not the probability calculus.
\end{enumerate}

PLN derives rules at the event level (Bayes' theorem, law of total
probability) and stores results at the evidence level.  There is no
contradiction because they concern different structures: Boolean for
events, Heyting for epistemic states.

\subsection{Heyting K\&S: The Interval Construction}
\label{sec:heytingks}

Although PLN's Bayesian rules operate at the Boolean event level, we
\emph{can} develop K\&S-like theory directly on Heyting algebras.  This
gives ``intuitionistic probability'' where the complement rule weakens
from equality to inequality.

\subsubsection{Modular Valuations}

On a bounded distributive lattice, a \textbf{modular valuation} is a
function $\nu: L \to [0,1]$ satisfying:
\begin{enumerate}
\item $\nu(\bot) = 0$, $\nu(\top) = 1$
\item Monotonicity: $a \leq b \Rightarrow \nu(a) \leq \nu(b)$
\item \textbf{Modularity}: $\nu(a) + \nu(b) = \nu(a \vee b) + \nu(a \wedge b)$
\end{enumerate}

The modularity axiom is the lattice-theoretic generalization of
inclusion-exclusion, expressed without requiring complements.

\subsubsection{Boolean vs Heyting Complements}

On a \textbf{Boolean} algebra, modularity implies:
$$\nu(a) + \nu(\neg a) = 1$$

On a \textbf{Heyting} algebra, we only get:
$$\nu(a) + \nu(\neg a) \leq 1$$

The \emph{slack} arises because $a \vee \neg a \leq \top$ in general
(excluded middle may fail).  This slack is precisely the
\textbf{excluded middle gap}:
$$\text{gap}(a) = 1 - \nu(a \vee \neg a) \geq 0$$

\subsubsection{The Interval Construction}

For a Heyting algebra with modular valuation $\nu$, define:
\begin{align*}
\text{lower}(a) &= \nu(a) \quad \text{(direct evidence for $a$)} \\
\text{upper}(a) &= 1 - \nu(\neg a) \quad \text{(absence of evidence against $a$)}
\end{align*}

Key properties:
\begin{itemize}
\item $\text{lower}(a) \leq \text{upper}(a)$ always (from the Heyting
  inequality)
\item $\text{upper}(a) - \text{lower}(a) = \text{gap}(a)$ (interval
  width equals excluded middle gap)
\item \textbf{Boolean collapse}: When $a \vee \neg a = \top$, the
  interval collapses to a point: $\text{lower}(a) = \text{upper}(a)$
\end{itemize}

\subsubsection{Interpretation}

In classical logic, knowing $\neg a$ tells you everything about $a$.
In intuitionistic logic, $\neg a$ only bounds $a$ from above.  The
interval $[\text{lower}(a), \text{upper}(a)]$ captures this
\emph{epistemic slack}:

\begin{itemize}
\item $\text{lower}(a) = \nu(a)$: ``how much evidence directly
  supports $a$''
\item $\text{upper}(a) = 1 - \nu(\neg a)$: ``how much room is left
  after accounting for $\neg a$''
\end{itemize}

This connects to imprecise probability (Walley) and credal sets (de
Cooman \& Hermans).  The 2D Evidence structure $(n^+, n^-)$ can be
seen as tracking both bounds simultaneously.

\subsection{The Beta Connection Revisited}

The \emph{hplus} operation (parallel aggregation):
$$(n^+_1, n^-_1) \oplus (n^+_2, n^-_2) = (n^+_1 + n^+_2, n^-_1 + n^-_2)$$
is precisely Beta conjugate updating.  When we observe independent evidence
from two sources, we simply add the counts---and this corresponds exactly
to updating the Beta parameters.

This complements Section~\ref{sec:truthvalue}: the algebraic operation
$\oplus$ \emph{is} Bayesian inference.

\subsection{The Unified Architecture}

The three perspectives converge:

\begin{center}
\begin{tabular}{lll}
\textbf{Framework} & \textbf{Operation} & \textbf{Interpretation} \\
\hline
Quantale & tensor $\otimes$ & Sequential composition, confidence compounding \\
Heyting algebra & meet/implication & Logical combination, non-Boolean bounds \\
Beta-Bernoulli & hplus $\oplus$ & Independent evidence, conjugate updating \\
\end{tabular}
\end{center}

The architectural insight: PLN's Evidence structure is a \emph{natural}
2D carrier that simultaneously satisfies quantale, Heyting, and Bayesian
constraints.  The two dimensions are not redundant---they encode
complementary aspects of uncertain inference.

\subsection{The Weight-Space Theorem}
\label{sec:weightspace}
This section formalizes a critical insight that has practical
implications for PLN implementations.

\subsubsection{The Problem}
When combining confidence values, one might naively compute:
$$c_{\text{combined}} = \texttt{w2c}(\min(c_1, c_2)) \quad \text{--- WRONG!}$$

This treats confidences as if they were weights.

\subsubsection{The Correct Formula}
$$c_{\text{combined}} = \texttt{w2c}(\min(\texttt{c2w}(c_1), \texttt{c2w}(c_2)))$$

Convert to weight space, take minimum, convert back.

\subsubsection{Why?}
The hypergeometric distribution operates on \emph{counts} (weights),
not confidences.  The mode bound:
$$\text{mode} \leq \min(a, b)$$
tells us that combined evidence is bounded by the minimum of input
evidence \emph{counts}.

Since confidence $c$ is a nonlinear transformation of weight $w$:
$$c = \frac{w}{w + k}, \quad w = \frac{k \cdot c}{1 - c}$$
taking $\min$ in confidence space gives incorrect results.  The error
can be \textbf{10--50\%} for high-confidence inputs.

\subsubsection{Practical Rule}
\textbf{Never store only (strength, confidence).}  You lose the
information needed for correct inference.

Options:
\begin{enumerate}
\item Store full Evidence $(n^+, n^-)$ --- \textbf{best}
\item Store (strength, weight) pairs
\item Store (strength, confidence, $k$) if $k$ is known
\end{enumerate}

\subsection{Comparison with NARS}
\label{sec:nars}
The Non-Axiomatic Reasoning System (NARS)~\cite{wang2013nal} shares
fundamental machinery with PLN:

\begin{center}
\begin{tabular}{lll}
\textbf{Aspect} & \textbf{PLN} & \textbf{NARS} \\
\hline
Weight transform & $w = c/(1-c)$ & Same \\
Confidence transform & $c = w/(w+k)$ & Same \\
Revision rule & Weighted average & Same \\
Derivation & Bayesian probability & Axiomatic (experience-grounded) \\
\end{tabular}
\end{center}

The weight/confidence bijection is proven:
$$\texttt{w2c}(\texttt{c2w}(c)) = c, \quad \texttt{c2w}(\texttt{w2c}(w)) = w$$

for valid inputs.  This means PLN and NARS compute equivalent results
for the revision rule---the philosophical difference (Bayesian vs.\
axiomatic) does not affect the mathematics.

\appendix
\section{Work in Progress}
\label{sec:wip}

\subsection{Markov Exchangeability}
For sequences that are not i.i.d.\ but exhibit first-order Markov
structure, a generalization of de~Finetti's theorem
applies~\cite{diaconisfreedman}.  In this setting, the sufficient
statistics are the \emph{transition counts}: how many times each
state-to-state transition occurred.  This suggests a ``Markov-PLN''
where evidence consists of a transition count matrix rather than
simple $(n^+, n^-)$ counts.

\subsection{Lean Statements of Main Theorems}

\paragraph{Theorem~\ref{thm:pln_optimal} (Predictor Collapse):}
The \texttt{RestrictedSolomonoffPrior} structure bundles a monotone machine
with a proof that its induced semimeasure is exchangeable.
\begin{lstlisting}[basicstyle=\scriptsize\ttfamily,frame=single,numbers=none]
structure RestrictedSolomonoffPrior where
  U : MonotoneMachine
  programs : Finset BinString
  hpf : PrefixFree programs
  hexch : ProgramsExchangeable U programs  -- the restriction!

theorem solomonoff_exchangeable_predictBit_same_counts
    (M : RestrictedSolomonoffPrior) :
    forall {n : N} (xs1 xs2 : Fin n -> Bool),
      countTrue xs1 = countTrue xs2 ->
      forall b : Bool,
        M.predictBit (List.ofFn xs1) b = M.predictBit (List.ofFn xs2) b
\end{lstlisting}

\paragraph{Theorem~\ref{thm:definetti} (De Finetti):}
\begin{lstlisting}[basicstyle=\scriptsize\ttfamily,frame=single,numbers=none]
theorem exchangeable_iff_bernoulliMixture (X : N -> Omega -> Bool)
    (mu : Measure Omega) [IsProbabilityMeasure mu]
    (hX : forall i, Measurable (X i)) :
    InfiniteExchangeable X mu <->
      exists (M : BernoulliMixture), Represents M X mu
\end{lstlisting}

\paragraph{Master Chain Theorem (\texorpdfstring{$\nuPLN$}{nuPLN} Justification):}
This theorem explicitly chains the four key results, making the full
derivation verifiable:
\begin{lstlisting}[basicstyle=\scriptsize\ttfamily,frame=single,numbers=none]
theorem nupln_master_chain (X : N -> Omega -> Bool) (mu : Measure Omega)
    [IsProbabilityMeasure mu] (hX : forall i, Measurable (X i))
    (hexch : InfiniteExchangeable X mu) :
    -- Part 1: De Finetti -> Bernoulli mixture
    exists (M : BernoulliMixture), Represents M X mu /\
    -- Part 2: Counts are sufficient statistics
    (forall n (xs1 xs2 : Fin n -> Bool),
      countTrue xs1 = countTrue xs2 -> M.prob xs1 = M.prob xs2) /\
    -- Part 3: PLN Evidence = counts
    (forall n_pos n_neg, evidenceFromCounts n_pos n_neg = (n_pos, n_neg)) /\
    -- Part 4: PLN strength -> posterior mean
    (forall eps, 0 < eps -> exists N, forall n_pos n_neg,
      n_pos + n_neg >= N -> n_pos + n_neg <> 0 ->
      |plnStrength n_pos n_neg - uniformPosteriorMean n_pos n_neg| < eps)
\end{lstlisting}

\paragraph{Inference Triad (Section~\ref{sec:triad}):}
\begin{lstlisting}[basicstyle=\scriptsize\ttfamily,frame=single,numbers=none]
-- Bayes inversion: P(A|B) = P(B|A) * P(B) / P(A)
def bayesInversion (s_BA s_A s_B : R) : R := s_BA * s_B / s_A

-- Induction = Bayes + Deduction
theorem plnInduction_eq_bayes_deduction (s_BA s_BC s_A s_B s_C : R) :
    plnInductionStrength s_BA s_BC s_A s_B s_C =
      plnDeductionStrength (bayesInversion s_BA s_A s_B) s_BC s_B s_C

-- Abduction = Bayes + Deduction
theorem plnAbduction_eq_bayes_deduction (s_AB s_CB s_A s_B s_C : R) :
    plnAbductionStrength s_AB s_CB s_A s_B s_C =
      plnDeductionStrength s_AB (bayesInversion s_CB s_B s_C) s_B s_C
\end{lstlisting}

All theorems are fully mechanized in Lean~4 with zero sorries.  The
de~Finetti proof constructs the mixing measure via the Hausdorff moment
theorem applied to the de~Finetti moment sequence.

\bibliographystyle{splncs04}
\bibliography{references}

\end{document}
